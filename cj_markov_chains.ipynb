{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake dataset 1 - prosty graf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake1 = pd.DataFrame([\n",
    "     {'prev':'START', 'next':'A', 'prob':0.3}\n",
    "    ,{'prev':'START', 'next':'B', 'prob':0.7}\n",
    "    ,{'prev':'A', 'next':'C', 'prob':0.2}\n",
    "    ,{'prev':'A', 'next':'D', 'prob':0.8}\n",
    "    ,{'prev':'B', 'next':'D', 'prob':1.0}\n",
    "    ,{'prev':'D', 'next':'C', 'prob':0.2}\n",
    "    ,{'prev':'C', 'next':'A', 'prob':0.3}\n",
    "    ,{'prev':'C', 'next':'N_CONV', 'prob':0.7}\n",
    "    ,{'prev':'D', 'next':'N_CONV', 'prob':0.1}\n",
    "    ,{'prev':'D', 'next':'CONV', 'prob':0.7}\n",
    "])\n",
    "\n",
    "print(fake1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler class\n",
    "Crawls through a given graph of transitions, producing conversion and non-conversion probabilities. With an optional argument a node (or a list of nodes) can be excluded from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    __graph = pd.DataFrame()\n",
    "    __active_crawlers = []\n",
    "    __paths = []\n",
    "    __probs_conv = []\n",
    "    __probs_n_conv = []\n",
    "    __current_index = 0\n",
    "    __verbose = False\n",
    "    __treshold = 3\n",
    "    __excluded_nodes = []\n",
    "    __step_count = 0\n",
    "    \n",
    "    def __init__(self, history, probs):\n",
    "        Crawler.__active_crawlers.append(self)\n",
    "        self.index = Crawler.__current_index\n",
    "        Crawler.__current_index += 1\n",
    "        self.history = history\n",
    "        self.probs = probs\n",
    "        Crawler.message('Created crawler{}, active crawlers: {} ({})'.format(self.index, len(Crawler.__active_crawlers), self.history))\n",
    "    \n",
    "    def __step(self):\n",
    "        current_node = self.history[-1]\n",
    "        exits = Crawler.__graph[Crawler.__graph['prev'] == current_node]['next'].to_list()\n",
    "        to_remove = []\n",
    "        for e in exits:\n",
    "            if (self.history.count(e) > Crawler.__treshold) or (e in Crawler.__excluded_nodes):\n",
    "                to_remove.append(e)\n",
    "        exits = list(set(exits) - set(to_remove))\n",
    "        if len(exits) == 0:\n",
    "            Crawler.message('Crawler{} finished'.format(self.index))\n",
    "            Crawler.message('\\tCrawler{}\\'s path: {} '.format(self.index, self.history))\n",
    "            Crawler.message('\\tCrawler{}\\'s probs: {} '.format(self.index, self.probs))\n",
    "            if current_node == 'CONV':\n",
    "                Crawler.__paths.append(self.history)\n",
    "                Crawler.__probs_conv.append(self.probs)\n",
    "            if current_node == 'N_CONV':\n",
    "                Crawler.__paths.append(self.history)\n",
    "                Crawler.__probs_n_conv.append(self.probs)\n",
    "\n",
    "        else:\n",
    "            for e in exits:             \n",
    "                p = Crawler.__graph.loc[(Crawler.__graph['prev'] == current_node) & (Crawler.__graph['next'] == e)]['prob'].to_list()\n",
    "                new = Crawler(self.history.copy(), self.probs.copy())\n",
    "                new.history.append(e)\n",
    "                new.probs += p\n",
    "                new.__step()\n",
    "        idx = self.index\n",
    "        Crawler.__active_crawlers.remove(self)\n",
    "        Crawler.message('Removed crawler{}, active crawlers: {}'.format(idx, len(Crawler.__active_crawlers)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def message(txt):\n",
    "        if Crawler.__verbose:\n",
    "            Crawler.__step_count += 1\n",
    "            step = Crawler.__step_count\n",
    "            t = Crawler.get_time()\n",
    "            print('{}: ({}) {}'.format(step, t, txt))\n",
    "            \n",
    "    @staticmethod\n",
    "    def set_verbose(verbose=True):\n",
    "        Crawler.__verbose = verbose\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def set_treshold(treshold=3):\n",
    "        Crawler.__treshold = treshold\n",
    "    \n",
    "    @staticmethod\n",
    "    def start():\n",
    "        if Crawler.__graph.empty:\n",
    "            Crawler.message('Before using Crawler you must load a graph! (Crawler.load_graph())')\n",
    "        else:\n",
    "            c0 = Crawler(['START'], [])\n",
    "            c0.__step()\n",
    "            \n",
    "    @staticmethod\n",
    "    def load_graph(graph, excluded_nodes = []):\n",
    "        Crawler.__graph = graph\n",
    "        Crawler.__excluded_nodes = excluded_nodes\n",
    "        \n",
    "    @staticmethod\n",
    "    def reset():\n",
    "        Crawler.__graph = pd.DataFrame()\n",
    "        Crawler.__active_crawlers = []\n",
    "        Crawler.__paths = []\n",
    "        Crawler.__probs_conv = []\n",
    "        Crawler.__probs_n_conv = []\n",
    "        Crawler.__current_index = 0\n",
    "        Crawler.__verbose = False\n",
    "        Crawler.__treshold = 3\n",
    "        Crawler.__excluded_nodes = []\n",
    "        Crawler.__step_count = 0\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_time():\n",
    "        return(datetime.now().strftime(\"%H:%M:%S.%f\"))\n",
    "            \n",
    "    @staticmethod\n",
    "    def result():\n",
    "        conv = 0\n",
    "        n_conv = 0\n",
    "        for plist in Crawler.__probs_conv:\n",
    "            conv += reduce(mul, plist)\n",
    "        for plist in Crawler.__probs_n_conv:\n",
    "            n_conv += reduce(mul, plist)\n",
    "        return(conv, n_conv)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov class\n",
    "Uses the Crawler class to loop through all the nodes in the graph and score them. The conversion score is given by the equation: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{score} = 1 - \\left(\\frac{\\text{conversion probability with the node excluded}}{\\text{conversion probability of the full graph}}\\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov:\n",
    "    def __init__(self, graph, depth=3):\n",
    "        self.graph = graph\n",
    "        self.depth = depth\n",
    "        self.nodes = self.__get_nodes()\n",
    "        self.prob_conv, self.prob_n_conv = self.__run_crawler(graph)\n",
    "        n_nodes = len(self.nodes)\n",
    "        results = {\n",
    "            'Node': self.nodes,\n",
    "            'prob_conv': [0] * n_nodes,\n",
    "            'prob_n_conv': [0] * n_nodes,\n",
    "            'score_conv': [0] * n_nodes,\n",
    "            'score_n_conv': [0] * n_nodes\n",
    "        }\n",
    "        self.results = pd.DataFrame(results).sort_values(by=['Node'])\n",
    "    \n",
    "    def __get_nodes(self):\n",
    "        prev_set = set(self.graph['prev'].to_list())\n",
    "        next_set = set(self.graph['next'].to_list())\n",
    "        neutral_set = set(['START', 'CONV', 'N_CONV'])\n",
    "        return(list(prev_set.union(next_set) - neutral_set))\n",
    "    \n",
    "    def __run_crawler(self, exclude = []):\n",
    "        Crawler.reset()\n",
    "        Crawler.load_graph(self.graph, exclude)\n",
    "        Crawler.set_treshold(self.depth)\n",
    "        Crawler.start()\n",
    "        return(Crawler.result())\n",
    "    \n",
    "    def __score(self,node):\n",
    "        node_prob_conv, node_prob_n_conv = self.__run_crawler(node)\n",
    "        score_conv = 1 - (node_prob_conv / self.prob_conv)\n",
    "        score_n_conv = 1 - (node_prob_n_conv / self.prob_n_conv)\n",
    "        self.results.loc[self.results['Node']==node, 'prob_conv'] = node_prob_conv\n",
    "        self.results.loc[self.results['Node']==node, 'prob_n_conv'] = node_prob_n_conv\n",
    "        self.results.loc[self.results['Node']==node, 'score_conv'] = score_conv\n",
    "        self.results.loc[self.results['Node']==node, 'score_n_conv'] = score_n_conv\n",
    "    \n",
    "    def run(self):\n",
    "        for n in self.nodes:\n",
    "            Markov.message('Scoring {}'.format(n))\n",
    "            self.__score(n)\n",
    "        print('Done.')\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_time():\n",
    "        return(datetime.now().strftime(\"%H:%M:%S.%f\"))\n",
    "    \n",
    "    @staticmethod\n",
    "    def message(txt):\n",
    "        t = Markov.get_time()\n",
    "        print('{}\\t{}'.format(t, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery cj_data\n",
    "SELECT prev_cluster prev, cluster next, N / SUM(N) OVER(PARTITION BY prev_cluster) prob\n",
    "FROM `mcw-play-217608.DECEMBER_2019_CLEAN.12_MARKOV_PAIRS`\n",
    "WHERE UPPER(prev_cluster) NOT LIKE \"%WEBSITE%\"\n",
    "AND UPPER(cluster) NOT LIKE \"%WEBSITE%\"\n",
    "AND N > 1000\n",
    "AND conversion_type IN ('non_conv', 'ret_off')\n",
    "AND prev_cluster != cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Markov(cj_data, 1)\n",
    "#m.run()\n",
    "#m.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
