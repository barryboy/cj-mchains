{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake dataset 1 - prosty graf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    prev    next  prob\n",
      "0  START       A   0.3\n",
      "1  START       B   0.7\n",
      "2      A       C   0.2\n",
      "3      A       D   0.8\n",
      "4      B       D   1.0\n",
      "5      D       C   0.2\n",
      "6      C       A   0.3\n",
      "7      C  N_CONV   0.7\n",
      "8      D  N_CONV   0.1\n",
      "9      D    CONV   0.7\n"
     ]
    }
   ],
   "source": [
    "fake1 = pd.DataFrame([\n",
    "     {'prev':'START', 'next':'A', 'prob':0.3}\n",
    "    ,{'prev':'START', 'next':'B', 'prob':0.7}\n",
    "    ,{'prev':'A', 'next':'C', 'prob':0.2}\n",
    "    ,{'prev':'A', 'next':'D', 'prob':0.8}\n",
    "    ,{'prev':'B', 'next':'D', 'prob':1.0}\n",
    "    ,{'prev':'D', 'next':'C', 'prob':0.2}\n",
    "    ,{'prev':'C', 'next':'A', 'prob':0.3}\n",
    "    ,{'prev':'C', 'next':'N_CONV', 'prob':0.7}\n",
    "    ,{'prev':'D', 'next':'N_CONV', 'prob':0.1}\n",
    "    ,{'prev':'D', 'next':'CONV', 'prob':0.7}\n",
    "])\n",
    "\n",
    "print(fake1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    graph = pd.DataFrame()\n",
    "    active_crawlers = []\n",
    "    paths = []\n",
    "    probs_conv = []\n",
    "    probs_n_conv = []\n",
    "    current_index = 0\n",
    "    verbose = False\n",
    "    treshold = 3\n",
    "    step_count = 0\n",
    "    \n",
    "    def __init__(self, history, probs):\n",
    "        if Crawler.graph.empty:\n",
    "            Crawler.message('Before using Crawler you must load a graph! (Crawler.load_graph())')\n",
    "        else:\n",
    "            Crawler.active_crawlers.append(self)\n",
    "            self.index = Crawler.current_index\n",
    "            Crawler.current_index += 1\n",
    "            self.history = history\n",
    "            self.probs = probs\n",
    "            Crawler.message('Created crawler{}, active crawlers: {} ({})'.format(self.index, len(Crawler.active_crawlers), self.history))\n",
    "    \n",
    "    def _step(self):\n",
    "        current_node = self.history[-1]\n",
    "        exits = Crawler.graph[Crawler.graph['prev'] == current_node]['next'].to_list()\n",
    "        for e in exits:\n",
    "            if self.history.count(e) > Crawler.treshold:\n",
    "                exits.remove(e)\n",
    "        if len(exits) == 0:\n",
    "            Crawler.message('Crawler{} finished'.format(self.index))\n",
    "            Crawler.message('\\tCrawler{}\\'s path: {} '.format(self.index, self.history))\n",
    "            Crawler.message('\\tCrawler{}\\'s probs: {} '.format(self.index, self.probs))\n",
    "            if current_node == 'CONV':\n",
    "                Crawler.paths.append(self.history)\n",
    "                Crawler.probs_conv.append(self.probs)\n",
    "            if current_node == 'N_CONV':\n",
    "                Crawler.paths.append(self.history)\n",
    "                Crawler.probs_n_conv.append(self.probs)\n",
    "\n",
    "        else:\n",
    "            for e in exits:             \n",
    "                p = Crawler.graph.loc[(Crawler.graph['prev'] == current_node) & (Crawler.graph['next'] == e)]['prob'].to_list()\n",
    "                new = Crawler(self.history.copy(), self.probs.copy())\n",
    "                new.history.append(e)\n",
    "                new.probs += p\n",
    "                new._step()\n",
    "        idx = self.index\n",
    "        Crawler.active_crawlers.remove(self)\n",
    "        Crawler.message('Removed crawler{}, active crawlers: {}'.format(idx, len(Crawler.active_crawlers)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def message(txt):\n",
    "        if Crawler.verbose:\n",
    "            Crawler.step_count += 1\n",
    "            step = Crawler.step_count\n",
    "            t = Crawler.get_time()\n",
    "            print('{}: ({}) {}'.format(step, t, txt))\n",
    "            \n",
    "    @staticmethod\n",
    "    def set_verbose(verbose=True):\n",
    "        Crawler.verbose = verbose\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def set_treshold(treshold=3):\n",
    "        Crawler.treshold = treshold\n",
    "    \n",
    "    @staticmethod\n",
    "    def start():\n",
    "        c0 = Crawler(['START'], [])\n",
    "        c0._step()\n",
    "            \n",
    "    @staticmethod\n",
    "    def load_graph(graph):\n",
    "        Crawler.graph = graph\n",
    "        \n",
    "    @staticmethod\n",
    "    def reset():\n",
    "        Crawler.graph = pd.DataFrame()\n",
    "        Crawler.active_crawlers = []\n",
    "        Crawler.paths = []\n",
    "        Crawler.probs_conv = []\n",
    "        Crawler.probs_n_conv = []\n",
    "        Crawler.current_index = 0\n",
    "        Crawler.verbose = False\n",
    "        Crawler.treshold = 3\n",
    "        Crawler.step_count = 0\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_time():\n",
    "        return(datetime.now().strftime(\"%H:%M:%S.%f\"))\n",
    "            \n",
    "    @staticmethod\n",
    "    def result():\n",
    "        conv = 0\n",
    "        n_conv = 0\n",
    "        for plist in Crawler.probs_conv:\n",
    "            conv += reduce(mul, plist)\n",
    "        for plist in Crawler.probs_n_conv:\n",
    "            n_conv += reduce(mul, plist)\n",
    "        return(conv, n_conv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7046793093222399, 0.29526082916352)\n"
     ]
    }
   ],
   "source": [
    "Crawler.reset()\n",
    "Crawler.load_graph(fake1)\n",
    "Crawler.set_treshold(3)\n",
    "#Crawler.set_verbose()\n",
    "Crawler.start()\n",
    "print(Crawler.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
